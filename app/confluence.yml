---
settings:
  artifacts-dir: results/confluence/%Y-%m-%d_%H-%M-%S
  aggregator: consolidator
  verbose: false
  check-updates: false    # disable bzt check for updates
  env:
    application_hostname: a4b78a3cab3364dbdb8afbea3a5f4685-2038387234.us-east-2.elb.amazonaws.com  # Confluence DC hostname without protocol, port and postfix e.g. test-confluence.atlassian.com or localhost
    application_protocol: http         # http or https
    application_port: 80               # 80, 443, 8080, 1990, etc
    secure: True                       # Set False to allow insecure connections, e.g. when using self-signed SSL certificate
    application_postfix: /confluence   # e.g. /confluence for TerraForm deployment url like `http://a1234-54321.us-east-2.elb.amazonaws.com/confluence`. Leave this value blank for url without postfix.
    admin_login: admin
    admin_password: admin

    #smartics or jmeter
    load_executor: locust              # jmeter and locust are supported. jmeter by default.
    concurrency: 20                   # number of concurrent virtual users for jmeter or locust scenario
    test_duration: 5m
    ramp-up: 5s                        # time to spin all concurrent users
    total_actions_per_hour: 2000
    WEBDRIVER_VISIBLE: False
    JMETER_VERSION: 5.6.3
    LANGUAGE: en_US.utf8
    allow_analytics: Yes               # Allow sending basic run analytics to Atlassian. These analytics help us to understand how the tool is being used and help us to continue to invest in this tooling. For more details please see our README.
    environment_compliance_check: True # Pre-test environment compliance validation. Set to "False" to skip it.
    extended_metrics: False
    # Action percentage for JMeter and Locust load executors
    view_page: 33
    view_dashboard: 10
    view_blog: 13
    search_cql: 4
    create_blog: 5
    create_and_edit_page: 9
    comment_page: 8
    view_attachment: 6
    upload_attachment: 7
    like_page: 3
    upload_emoticon: 4      # For Confluence 8.4.x+
    standalone_extension: 0 # By default disabled
    standalone_extension_us_rest_content: 5
    #smartics
    #standalone_extension_section: 10 # By default disabled
    #standalone_extension_hide: 10 # By default disabled
    #standalone_extension_hidefromreader: 10 # By default disabled
    #standalone_extension_hidefromanonymous: 10 # By default disabled

    #    view_page: 0
    #    view_dashboard: 0
    #    view_blog: 0
    #    search_cql: 0
    #    create_blog: 0
    #    create_and_edit_page: 0
    #    comment_page: 0
    #    view_attachment: 0
    #    upload_attachment: 0
    #    like_page: 0
    #    upload_emoticon: 0      # For Confluence 8.4.x+
    # standalone_extension: 50 # By default disabled (0)

    # Custom dataset section.
    custom_dataset_query: space='MAN1' AND title ~ 'Versuch*' 
    # Write CQL query to add CQL output to the app/datasets/confluence/custom_pages.csv, e.g. "title ~ 'AppPage*'"
    # custom_dataset_query:  # Write CQL query to add CQL output to the app/datasets/confluence/custom_pages.csv, e.g. "title ~ 'AppPage*'"
    # Write CQL query to add CQL output to the app/datasets/confluence/custom_pages.csv, e.g. "title ~ 'AppPage*'"
    #smartics compared
    # custom_dataset_query:
    #    custom_dataset_query:  "space='PROJECTDOCTEST' AND (title = 'Test Case Display Table' OR title =  'Test Case Transclude from Documents')"
    # custom_dataset_query:   # Write CQL query to add CQL output to the app/datasets/confluence/custom_pages.csv, e.g. "title ~ 'AppPage*'"
    custom_dataset_query:  "title ~ 'DCPTCONTENT1 Home' OR title ~ 'Versuch A'"  # Write CQL query to add CQL output to the app/datasets/confluence/custom_pages.csv, e.g. "title ~ 'AppPage*'"
    # custom_dataset_query: title ~ 'smarticsUserScriptPage'          # Write CQL query to add CQL output to the app/datasets/confluence/custom_pages.csv, e.g. "title ~ 'AppPage*'"
services:
  - module: shellexec
    prepare:
      - python util/pre_run/environment_checker.py
      - python util/pre_run/environment_compliance_check.py confluence
      - python util/data_preparation/confluence_prepare_data.py
    shutdown:
      - python util/post_run/jmeter_post_check.py
      - python util/jtl_convertor/jtls-to-csv.py kpi.jtl selenium.jtl
    post-process:
      - python util/analytics/analytics.py confluence
      - python util/post_run/cleanup_results_dir.py
  - module: pip-install
    packages:
      - selenium==4.31.0
execution:
  - scenario: ${load_executor}
    executor: ${load_executor}
    concurrency: ${concurrency}
    hold-for: ${test_duration}
    ramp-up: ${ramp-up}
  - scenario: selenium
    executor: selenium
    runner: pytest
    hold-for: ${test_duration}
scenarios:
  selenium:
    script: selenium_ui/confluence_ui.py
  locust:
    script: locustio/confluence/locustfile.py
  jmeter:
    script: jmeter/confluence.jmx
    properties:
      application_hostname: ${application_hostname}
      application_protocol: ${application_protocol}
      application_port: ${application_port}
      application_postfix: ${application_postfix}
      # Workload model
      total_actions_per_hr: ${total_actions_per_hour}
      perc_view_page: ${view_page}
      perc_view_dashboard: ${view_dashboard}
      perc_view_blog: ${view_blog}
      perc_search_cql: ${search_cql}
      perc_create_blog: ${create_blog}
      perc_create_and_edit_page: ${create_and_edit_page}
      perc_comment_page: ${comment_page}
      perc_view_attachment: ${view_attachment}
      perc_upload_attachment: ${upload_attachment}
      perc_like_page: ${like_page}
      perc_upload_emoticon: ${upload_emoticon}
      perc_standalone_extension: ${standalone_extension}
modules:
  consolidator:
    rtimes-len: 0 # CONFSRVDEV-7631 reduce sampling
    percentiles: [] # CONFSRVDEV-7631 disable all percentiles due to Taurus's excessive memory usage
  jmeter:
    version: ${JMETER_VERSION}
    detect-plugins: true
    memory-xmx: 8G  # allow JMeter to use up to 8G of memory
    plugins:
      - jpgc-casutg=2.10
      - jpgc-dummy=0.4
      - jpgc-ffw=2.0
      - jpgc-fifo=0.2
      - jpgc-functions=2.2
      - jpgc-json=2.7
      - jpgc-perfmon=2.1
      - jpgc-prmctl=0.4
      - jpgc-tst=2.6
      - bzm-random-csv=0.8    # not used default jmx file
    system-properties:
      server.rmi.ssl.disable: true
      java.rmi.server.hostname: localhost
      httpsampler.ignore_failed_embedded_resources: "true"
  selenium:
    chromedriver:
#      version: "126.0.6478.126"
#      version: "101.0.4951.41" # Supports Chrome version 101. You can refer to http://chromedriver.chromium.org/downloads
#      version: "90.0.4430.24" # Supports Chrome version 97. You can refer to http://chromedriver.chromium.org/downloads
#      version: "102.0.5005.61" # Supports Chrome version 102. You can refer to http://chromedriver.chromium.org/downloads
#      version: "103.0.5060.134" # Supports Chrome version 103. You can refer to http://chromedriver.chromium.org/downloads
#      version: "114.0.5735.90" # Supports Chrome version 103. You can refer to http://chromedriver.chromium.org/downloads
#      version: "118.0.5993.70" # Supports Chrome version 118. You can refer to https://googlechromelabs.github.io/chrome-for-testing
#      version: "130.0.6723.91" # Supports Chrome version 130. You can refer to https://googlechromelabs.github.io/chrome-for-testing
#      version: "137.0.7151.70" # Supports Chrome version 137. You can refer to https://googlechromelabs.github.io/chrome-for-testing
      version: "138.0.7204.92" 
        #  blazemeter:
    # token: e41bf0cde4ff5c5d75ba5e5ee9aa200e85bfe870a51262efdf4a4e6dcb084f3a677dcb25
    # address: https://a.blazemeter.com  # reporting service address
    # data-address: https://data.blazemeter.com  # data service address
#    browser-open: none  # auto-open the report in browser,
    # can be "start", "end", "both", "none"
    # send-interval: 30s   # send data each n-th second
    # timeout: 5s  # connect and request timeout for BlazeMeter API
    # artifact-upload-size-limit: 5  # limit max size of file (in megabytes)
    # that goes into zip for artifact upload, 10 by default
    # following instructions will have effect when no per-reporter settings
#    report-name:  ask # if you will use value 'ask', it will ask it from command line
    #  modules.blazemeter.report-name="example-1"
#    test: regression-example
#    project: projectdoc
reporting:
- data-source: sample-labels
  module: junit-xml
- module: passfail
  criteria:
  - failures>25% over 300s, stop as failed
